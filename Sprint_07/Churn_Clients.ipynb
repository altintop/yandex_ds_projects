{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение с учителем\n",
    "# Прогнозирование ухода клиента из банка в ближайшее время\n",
    "## Описание проекта\n",
    "Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.  \n",
    "\n",
    "Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком.  \n",
    "\n",
    "Постройте модель с предельно большим значением F1-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте F1-меру на тестовой выборке самостоятельно.  \n",
    "\n",
    "Дополнительно измеряйте AUC-ROC, сравнивайте её значение с F1-мерой.  \n",
    "\n",
    "Источник данных: https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание данных\n",
    "Признаки\n",
    "- **RowNumber** — индекс строки в данных\n",
    "- **CustomerId** — уникальный идентификатор клиента\n",
    "- **Surname** — фамилия\n",
    "- **CreditScore** — кредитный рейтинг\n",
    "- **Geography** — страна проживания\n",
    "- **Gender** — пол\n",
    "- **Age** — возраст\n",
    "- **Tenure** — количество недвижимости у клиента\n",
    "- **Balance** — баланс на счёте\n",
    "- **NumOfProducts** — количество продуктов банка, используемых клиентом\n",
    "- **HasCrCard** — наличие кредитной карты\n",
    "- **IsActiveMember** — активность клиента\n",
    "- **EstimatedSalary** — предполагаемая зарплата\n",
    "\n",
    "Целевой признак\n",
    "- **Exited** — факт ухода клиента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 1. Загрузите и подготовьте данные. Поясните порядок действий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт нужных библиотек и классов\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "# Алгоритм классификации - решающее дерево\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Алгоритм классификации - случайный лес\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Алгоритм классификации - логистическая регрессия\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Механизм GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Механизм StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# Метрика F1\n",
    "from sklearn.metrics import f1_score\n",
    "# Метрика AUC-ROC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# Метрика \"Точность\"\n",
    "from sklearn.metrics import precision_score\n",
    "# Метрика \"Полнота\"\n",
    "from sklearn.metrics import recall_score\n",
    "# Инструмент перемешивания объектов\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df = pd.read_csv('churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9091.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>4.997690</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.894723</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age       Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  9091.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800     4.997690   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806     2.894723   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000     0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000     2.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000     5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000     7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000    10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df.info()\n",
    "churn_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из описания видно, что:\n",
    " 1. Можно избавиться от столбца **RowNumber**, т.к. его значения содержатся в индексе.\n",
    " 2. Можно избавиться от столбца **Surname**, т.к. он в нашей задаче не нужен.\n",
    " 3. Переименовать столбцы в привычную нотацию\n",
    " 4. Переименовать **Geography** => **country**, **HasCrCard** => **has_credit_card**, **IsActiveMember** => **is_active**, **NumOfProducts** => **product_count**, **Exited** => **is_exited**\n",
    " 4. С помощью OHE-кодирования избавиться от столбцов **country** и **female**\n",
    " 5. Убрать из рассмотрения строки, где tenure равен null, т.к. не совсем понятно как заполнить данный пропуск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df = churn_df.drop('RowNumber', axis=1)\n",
    "churn_df = churn_df.drop('Surname', axis=1)\n",
    "churn_df.columns = ['customer_id', 'credit_score', 'country', 'gender', 'age', 'tenure', 'balance', 'product_count', 'has_credit_card', 'is_active', 'estimated_salary', 'is_exited']\n",
    "churn_df = pd.get_dummies(churn_df, drop_first=True)\n",
    "churn_df = churn_df[~churn_df['tenure'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>product_count</th>\n",
       "      <th>has_credit_card</th>\n",
       "      <th>is_active</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>is_exited</th>\n",
       "      <th>country_Germany</th>\n",
       "      <th>country_Spain</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>15634602</td>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>15647311</td>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>15619304</td>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>15701354</td>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>15737888</td>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  credit_score  age  tenure    balance  product_count  \\\n",
       "0     15634602           619   42     2.0       0.00              1   \n",
       "1     15647311           608   41     1.0   83807.86              1   \n",
       "2     15619304           502   42     8.0  159660.80              3   \n",
       "3     15701354           699   39     1.0       0.00              2   \n",
       "4     15737888           850   43     2.0  125510.82              1   \n",
       "\n",
       "   has_credit_card  is_active  estimated_salary  is_exited  country_Germany  \\\n",
       "0                1          1         101348.88          1                0   \n",
       "1                0          1         112542.58          0                0   \n",
       "2                1          0         113931.57          1                0   \n",
       "3                0          0          93826.63          0                0   \n",
       "4                1          1          79084.10          0                0   \n",
       "\n",
       "   country_Spain  gender_Male  \n",
       "0              0            0  \n",
       "1              1            0  \n",
       "2              0            0  \n",
       "3              0            0  \n",
       "4              1            0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 2. Исследуйте баланс классов, обучите модель без учёта дисбаланса. Кратко опишите выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "churn_df.shape =  (9091, 13)\n",
      "churn_df_zeros.shape =  (7237, 13)\n",
      "churn_df_ones.shape =  (1854, 13)\n"
     ]
    }
   ],
   "source": [
    "churn_df_zeros = churn_df[churn_df['is_exited'] == 0]\n",
    "churn_df_ones = churn_df[churn_df['is_exited'] == 1]\n",
    "print('churn_df.shape = ', churn_df.shape)\n",
    "print('churn_df_zeros.shape = ', churn_df_zeros.shape)\n",
    "print('churn_df_ones.shape = ', churn_df_ones.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что объектов положительного класса примерно в 4 раза меньше, чем объектов отрицательного класса. Попробуем обучить модель без учёта дисбаланса классов.  \n",
    "\n",
    "### Подготовка данных к обучению\n",
    "Сначала выделим features и target признаки, а затем разделим исходные данные на обучающую, валидационную и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сначала выделим features и target признаки\n",
    "features = churn_df.drop(['is_exited'], axis=1)\n",
    "target = churn_df['is_exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делить исходные данные будем в пропорциях: Обучающая выборка 60%, Валидационная 20% и Тестовая 20%\n",
    "Для этого воспользуемся методом train_test_split из библиотеки sklearn. Она делит исходные данные на 2 части, следовательно применять её надо 2 раза.\n",
    "Сначала поделим выделим тестовую выборку (20% от исх.), а потом из большего остатка (80% от исх.) выделим обучающую и валидационную выборки (по 75% и 25% от остатка соответственно)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_comb, features_test, target_comb, target_test = train_test_split(features, target, test_size=0.2, random_state=12345)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features_comb, target_comb, test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор гиперпараметров моделей\n",
    "Попробуем подобрать оптимальные настройки моделей с помощью механизма GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 7}\n",
      "0.5616553162962769\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=12345, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "# Подбор параметра max_depth для модели решающего дерева\n",
    "dtc = DecisionTreeClassifier(random_state=12345)\n",
    "param_grid = { \n",
    "    'max_depth' : list(range(1, 10)),\n",
    "}\n",
    "k_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "CV_dtc = GridSearchCV(estimator=dtc, param_grid=param_grid, cv= k_fold, scoring = 'f1')\n",
    "CV_dtc.fit(features_train, target_train)\n",
    "print(CV_dtc.best_params_)\n",
    "print(CV_dtc.best_score_)\n",
    "print(CV_dtc.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подбор параметров n_estimators и max_depth для модели случайного леса\n",
    "rfc = RandomForestClassifier(random_state=12345)\n",
    "param_grid = { \n",
    "    'n_estimators': list(range(2, 21, 2)),\n",
    "    'max_depth' : list(range(2, 17, 2)),\n",
    "}\n",
    "k_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= k_fold, scoring = 'f1')\n",
    "# Операция занимает долгое время, поэтому следующие команды закоментированы по умолчанию\n",
    "# (результат подбора: {'max_depth': 10, 'n_estimators': 18})\n",
    "#CV_rfc.fit(features_train, target_train)\n",
    "#print(CV_rfc.best_params_)\n",
    "#print(CV_rfc.best_score_)\n",
    "#print(CV_rfc.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, для модели решающего дерева самая лучшая максимальная глубина равна 7, а для модели случайного леса макс. глубина равна 10, кол-во деревьев - 18."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расчёт метрик F1 и AUC-ROC для найденных моделей решающего дерева и случайного леса, а также для логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier model has f1 = 0.568 and auc_roc = 0.819\n"
     ]
    }
   ],
   "source": [
    "# Модель решающего дерева\n",
    "model = DecisionTreeClassifier(max_depth=7, random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "f1 = f1_score(target_valid, predicted_valid)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('DecisionTreeClassifier model has f1 =', '%.3f'%f1, 'and auc_roc =', '%.3f'%auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier model has f1 = 0.513 and auc_roc = 0.831\n"
     ]
    }
   ],
   "source": [
    "# Модель случайного леса\n",
    "model = RandomForestClassifier(max_depth=10, n_estimators=18, random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "f1 = f1_score(target_valid, predicted_valid)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('RandomForestClassifier model has f1 =', '%.3f'%f1, 'and auc_roc =', '%.3f'%auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression model has f1 = 0.0 precision = 0.0 recall = 0.0 and auc_roc = 0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Модель логистической регрессии\n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "precision = precision_score(target_valid, predicted_valid)\n",
    "recall = recall_score(target_valid, predicted_valid)\n",
    "f1 = f1_score(target_valid, predicted_valid)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('LogisticRegression model has f1 =', f1, 'precision =', precision, 'recall =', recall, 'and auc_roc =', '%.3f'%auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "По метрике F1 лучше всех справилась модель решающего дерева. По метрике AUC-ROC лучше всех оказалась модель случайного леса. Но видим, что до 1 обеим метрикам ещё далеко.  \n",
    "Логистическая регрессия вообще не смогла предсказать ни одного объекта с положительным классом и метрика F1 у нее равна 0.  \n",
    "\n",
    "Попробуем улучшить модели за счёт балансировки классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 3. Улучшите качество модели, учитывая дисбаланс классов. Обучите разные модели и найдите лучшую. Кратко опишите выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Взвешивание классов\n",
    "Начнём с технологии взвешивания классов, для этого в моделях надо указать параметр **class_weight='balanced'**.  \n",
    "Сначала подберём гиперпараметры для моделей решающего дерева и случайного леса, а затем проверим обученные модели на валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5}\n",
      "0.5756024524503323\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=5,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=12345, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "# Подбор параметра max_depth для модели решающего дерева\n",
    "dtc = DecisionTreeClassifier(random_state=12345, class_weight='balanced')\n",
    "param_grid = { \n",
    "    'max_depth' : list(range(1, 10)),\n",
    "}\n",
    "k_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "CV_dtc = GridSearchCV(estimator=dtc, param_grid=param_grid, cv= k_fold, scoring = 'f1')\n",
    "CV_dtc.fit(features_train, target_train)\n",
    "print(CV_dtc.best_params_)\n",
    "print(CV_dtc.best_score_)\n",
    "print(CV_dtc.best_estimator_)\n",
    "\n",
    "# Подбор параметров n_estimators и max_depth для модели случайного леса\n",
    "rfc = RandomForestClassifier(random_state=12345, class_weight='balanced')\n",
    "param_grid = { \n",
    "    'n_estimators': list(range(2, 31, 2)),\n",
    "    'max_depth' : list(range(2, 17, 2)),\n",
    "}\n",
    "k_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= k_fold, scoring = 'f1')\n",
    "# Операция занимает долгое время, поэтому следующие команды закоментированы по умолчанию \n",
    "# (результат подбора: {'max_depth': 10, 'n_estimators': 20})\n",
    "#CV_rfc.fit(features_train, target_train)\n",
    "#print(CV_rfc.best_params_)\n",
    "#print(CV_rfc.best_score_)\n",
    "#print(CV_rfc.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier model has f1 = 0.54 and auc_roc = 0.81\n",
      "RandomForestClassifier model has f1 = 0.59 and auc_roc = 0.84\n",
      "LogisticRegression model has f1 = 0.48 and auc_roc = 0.76\n"
     ]
    }
   ],
   "source": [
    "# Модель решающего дерева\n",
    "model = DecisionTreeClassifier(max_depth=5, random_state=12345, class_weight='balanced')\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "f1 = f1_score(target_valid, predicted_valid)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "joblib.dump(model, 'dtr_model_bal.joblib')\n",
    "print('DecisionTreeClassifier model has f1 =', '%.2f'%f1, 'and auc_roc =', '%.2f'%auc_roc)\n",
    "\n",
    "# Модель случайного леса\n",
    "model = RandomForestClassifier(max_depth=10, n_estimators=20, random_state=12345, class_weight='balanced')\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "f1 = f1_score(target_valid, predicted_valid)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "joblib.dump(model, 'rfc_model_bal.joblib')\n",
    "print('RandomForestClassifier model has f1 =', '%.2f'%f1, 'and auc_roc =', '%.2f'%auc_roc)\n",
    "\n",
    "# Модель логистической регрессии\n",
    "model = LogisticRegression(random_state=12345, solver='liblinear', class_weight='balanced')\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "precision = precision_score(target_valid, predicted_valid)\n",
    "recall = recall_score(target_valid, predicted_valid)\n",
    "f1 = f1_score(target_valid, predicted_valid)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "joblib.dump(model, 'lr_model_bal.joblib')\n",
    "print('LogisticRegression model has f1 =', '%.2f'%f1, 'and auc_roc =', '%.2f'%auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "По метрикам F1 и AUC-ROC лучше всех справилась модель случайного леса, с ней мы достигли значения F1=0.59, которое требовалось в задании проекта.  \n",
    "Модель логистической регрессии улучшила свои показатели и теперь метрика F1 у неё равна 0.48.  \n",
    "Попытаемся сделать наши модели ещё лучше за счёт увеличения выборки.\n",
    "\n",
    "### Увеличение выборки\n",
    "Т.к. объктов положительного класса примерно в 4 раза меньше, чем объектов отрицательного класса, то попробуем увеличить кол-во объектов положительного класса в 4 раза, и тогда должен наступить баланс классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция увеличения выборки\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9}\n",
      "0.8313530324288924\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=9,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=12345, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "# Подбор параметра max_depth для модели решающего дерева\n",
    "dtc = DecisionTreeClassifier(random_state=12345)\n",
    "param_grid = { \n",
    "    'max_depth' : list(range(1, 10)),\n",
    "}\n",
    "k_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "CV_dtc = GridSearchCV(estimator=dtc, param_grid=param_grid, cv= k_fold, scoring = 'f1')\n",
    "CV_dtc.fit(features_upsampled, target_upsampled)\n",
    "print(CV_dtc.best_params_)\n",
    "print(CV_dtc.best_score_)\n",
    "print(CV_dtc.best_estimator_)\n",
    "\n",
    "# Подбор параметров n_estimators и max_depth для модели случайного леса\n",
    "rfc = RandomForestClassifier(random_state=12345)\n",
    "param_grid = { \n",
    "    'n_estimators': list(range(2, 31, 2)),\n",
    "    'max_depth' : list(range(2, 17, 2)),\n",
    "}\n",
    "k_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= k_fold, scoring = 'f1')\n",
    "# Операция занимает долгое время, поэтому следующие команды закоментированы по умолчанию \n",
    "# (результат подбора: {'max_depth': 16, 'n_estimators': 28})\n",
    "#CV_rfc.fit(features_upsampled, target_upsampled)\n",
    "#print(CV_rfc.best_params_)\n",
    "#print(CV_rfc.best_score_)\n",
    "#print(CV_rfc.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier model has f1 = 0.54 and auc_roc = 0.78\n",
      "RandomForestClassifier model has f1 = 0.57 and auc_roc = 0.84\n",
      "LogisticRegression model has f1 = 0.35 and auc_roc = 0.56\n"
     ]
    }
   ],
   "source": [
    "# Модель решающего дерева\n",
    "model = DecisionTreeClassifier(max_depth=9, random_state=12345)\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "f1 = f1_score(target_valid, predicted_valid)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "joblib.dump(model, 'dtr_model_up.joblib')\n",
    "print('DecisionTreeClassifier model has f1 =', '%.2f'%f1, 'and auc_roc =', '%.2f'%auc_roc)\n",
    "\n",
    "# Модель случайного леса\n",
    "model = RandomForestClassifier(max_depth=16, n_estimators=28, random_state=12345)\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "f1 = f1_score(target_valid, predicted_valid)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "joblib.dump(model, 'rfc_model_up.joblib')\n",
    "print('RandomForestClassifier model has f1 =', '%.2f'%f1, 'and auc_roc =', '%.2f'%auc_roc)\n",
    "\n",
    "# Модель логистической регрессии\n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "precision = precision_score(target_valid, predicted_valid)\n",
    "recall = recall_score(target_valid, predicted_valid)\n",
    "f1 = f1_score(target_valid, predicted_valid)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "joblib.dump(model, 'lr_model_up.joblib')\n",
    "print('LogisticRegression model has f1 =', '%.2f'%f1, 'and auc_roc =', '%.2f'%auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "Как видим увеличение выборки не помогло улучшить значение метрики F1. Попробуем воспользоваться уменьшением выборки.\n",
    "### Уменьшение выборки\n",
    "Т.к. объктов положительного класса примерно в 4 раза меньше, чем объектов отрицательного класса, то попробуем оставить одну четверть от объектов отрицательного класса, и тогда должен наступить баланс классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция уменьшения выборки\n",
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    \n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345)\n",
    "    \n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_downsampled, target_downsampled = downsample(features_train, target_train, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4}\n",
      "0.7460979428403552\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=12345, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "# Подбор параметра max_depth для модели решающего дерева\n",
    "dtc = DecisionTreeClassifier(random_state=12345)\n",
    "param_grid = { \n",
    "    'max_depth' : list(range(1, 10)),\n",
    "}\n",
    "k_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "CV_dtc = GridSearchCV(estimator=dtc, param_grid=param_grid, cv= k_fold, scoring = 'f1')\n",
    "CV_dtc.fit(features_downsampled, target_downsampled)\n",
    "print(CV_dtc.best_params_)\n",
    "print(CV_dtc.best_score_)\n",
    "print(CV_dtc.best_estimator_)\n",
    "\n",
    "# Подбор параметров n_estimators и max_depth для модели случайного леса\n",
    "rfc = RandomForestClassifier(random_state=12345)\n",
    "param_grid = { \n",
    "    'n_estimators': list(range(2, 31, 2)),\n",
    "    'max_depth' : list(range(2, 17, 2)),\n",
    "}\n",
    "k_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= k_fold, scoring = 'f1')\n",
    "# Операция занимает долгое время, поэтому следующие команды закоментированы по умолчанию \n",
    "# (результат подбора: {'max_depth': 6, 'n_estimators': 24})\n",
    "#CV_rfc.fit(features_downsampled, target_downsampled)\n",
    "#print(CV_rfc.best_params_)\n",
    "#print(CV_rfc.best_score_)\n",
    "#print(CV_rfc.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier model has f1 = 0.49 and auc_roc = 0.79\n",
      "RandomForestClassifier model has f1 = 0.57 and auc_roc = 0.85\n",
      "LogisticRegression model has f1 = 0.35 and auc_roc = 0.57\n"
     ]
    }
   ],
   "source": [
    "# Модель решающего дерева\n",
    "model = DecisionTreeClassifier(max_depth=4, random_state=12345)\n",
    "model.fit(features_downsampled, target_downsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "f1 = f1_score(target_valid, predicted_valid)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "joblib.dump(model, 'dtr_model_down.joblib')\n",
    "print('DecisionTreeClassifier model has f1 =', '%.2f'%f1, 'and auc_roc =', '%.2f'%auc_roc)\n",
    "\n",
    "# Модель случайного леса\n",
    "model = RandomForestClassifier(max_depth=6, n_estimators=24, random_state=12345)\n",
    "model.fit(features_downsampled, target_downsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "f1 = f1_score(target_valid, predicted_valid)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "joblib.dump(model, 'rfc_model_down.joblib')\n",
    "print('RandomForestClassifier model has f1 =', '%.2f'%f1, 'and auc_roc =', '%.2f'%auc_roc)\n",
    "\n",
    "# Модель логистической регрессии\n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_downsampled, target_downsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "precision = precision_score(target_valid, predicted_valid)\n",
    "recall = recall_score(target_valid, predicted_valid)\n",
    "f1 = f1_score(target_valid, predicted_valid)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "joblib.dump(model, 'lr_model_down.joblib')\n",
    "print('LogisticRegression model has f1 =', '%.2f'%f1, 'and auc_roc =', '%.2f'%auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "Уменьшение выборки не позволило добиться увеличения значения метрики F1.  \n",
    "Таким образом, получаем, что самые лучшие модели - это модели случайного леса. Все три варианта этой модели имеют примерно одинакоовое значение метрики F1 - поэтому проведём финальное тестирование на тестовой выборке для всех 3 вариантов.\n",
    "\n",
    "## Шаг 4. Проведите финальное тестирование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier rfc_model_bal.joblib has f1 = 0.57 and auc_roc = 0.85\n",
      "RandomForestClassifier rfc_model_up.joblib has f1 = 0.59 and auc_roc = 0.85\n",
      "RandomForestClassifier rfc_model_down.joblib has f1 = 0.58 and auc_roc = 0.84\n"
     ]
    }
   ],
   "source": [
    "def rfc_test(model_name):\n",
    "    model = joblib.load(model_name)\n",
    "    predicted_test = model.predict(features_test)\n",
    "    f1 = f1_score(target_test, predicted_test)\n",
    "    probabilities_test = model.predict_proba(features_test)\n",
    "    probabilities_one_test = probabilities_test[:, 1]\n",
    "    auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "    print('RandomForestClassifier', model_name, 'has f1 =', '%.2f'%f1, 'and auc_roc =', '%.2f'%auc_roc)\n",
    "\n",
    "rfc_test('rfc_model_bal.joblib')\n",
    "rfc_test('rfc_model_up.joblib')\n",
    "rfc_test('rfc_model_down.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "На тестовой выборке мы также получили примерно одинаковые значения по метрикам F1 и AUC-ROC. Также в ходе выполнения проекта было замечено, что метрика AUC-ROC всегда превосходит метрику F1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
